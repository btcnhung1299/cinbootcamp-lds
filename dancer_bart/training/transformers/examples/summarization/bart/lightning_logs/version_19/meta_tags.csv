key,value
output_dir,/root/lds/transformers/examples/summarization/bart/bart_sum
fp16,False
fp16_opt_level,O1
n_gpu,1
n_tpu_cores,0
max_grad_norm,1.0
do_train,True
do_predict,False
gradient_accumulation_steps,1
seed,42
model_name_or_path,bart-large
config_name,
tokenizer_name,
cache_dir,
learning_rate,1e-07
weight_decay,0.0
adam_epsilon,1e-08
warmup_steps,0
num_train_epochs,3
train_batch_size,2
eval_batch_size,32
max_source_length,1024
max_target_length,256
data_dir,../../../../encoding/
